{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectored Read and Write Vectors Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadVector(M_t, w_t):\n",
    "    '''\n",
    "    Computes the Read Vector of EACH HEAD for the entire Batch at once.\n",
    "    \n",
    "    M_t: Memory of size (Batch_size,N,M) at time t.\n",
    "    w_t: (Batch_size,N), Weighting generated by READ HEAD at time t for reading memory location\n",
    "    \n",
    "    RETURNS:\n",
    "    \n",
    "    r_t: (Batch_size,M) The Read Vector\n",
    "    '''\n",
    "    batch_size,N,M = M_t.shape[0], M_t.shape[1], M_t.shape[2]\n",
    "    \n",
    "    #tol = 0.01\n",
    "    #assert (np.sum(w_t) >= 1.0 - tol) & (np.sum(w_t) <= 1.0 + tol)\n",
    "    r_t = tf.reshape(  tf.matmul(tf.reshape(w_t,(batch_size,1,N)),M_t), (batch_size,M)   )\n",
    "    \n",
    "    #assert r_t.shape == (batch_size,M)\n",
    "    \n",
    "    return r_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 68\n",
    "features = 8\n",
    "inputs = tf.random.uniform((batch_size,features))\n",
    "n_RH = 2\n",
    "n_WH = 2\n",
    "N = 100\n",
    "M = 20\n",
    "M_prev = tf.random.uniform((batch_size,N,M))\n",
    "w_t = tf.random.uniform((batch_size,N))\n",
    "a_t = tf.random.uniform((batch_size,M))\n",
    "e_t = tf.random.uniform((batch_size,M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.9 ms ± 451 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.array([np.dot(w_t[i],M_prev[i]) for i in range(batch_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_reshaped = tf.reshape(w_t,(w_t.shape[0],1,w_t.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([54, 1, 120])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([54, 120, 28])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_prev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=46435, shape=(54, 1, 28), dtype=float32, numpy=\n",
       "array([[[32.767307, 29.67947 , 29.991352, ..., 31.570396, 33.52847 ,\n",
       "         34.785275]],\n",
       "\n",
       "       [[28.586918, 29.211546, 30.81921 , ..., 31.666348, 26.021385,\n",
       "         30.774918]],\n",
       "\n",
       "       [[32.036026, 30.057602, 30.28217 , ..., 30.137281, 30.679464,\n",
       "         26.555609]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[29.969158, 30.04381 , 30.72913 , ..., 28.836475, 31.721498,\n",
       "         28.783731]],\n",
       "\n",
       "       [[31.592222, 29.157991, 31.915648, ..., 31.20196 , 27.410116,\n",
       "         30.2157  ]],\n",
       "\n",
       "       [[31.946661, 28.97745 , 26.739243, ..., 27.836405, 28.473106,\n",
       "         25.06023 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tf.reshape(w_t,(batch_size,1,N)),M_prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.03 ms ± 605 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ReadVector(M_prev,w_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much Faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Vector Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteOnMemory(M_prev, w_t, e_t, a_t):\n",
    "    \n",
    "    '''\n",
    "    Computes the updated Memory Matrix for the each example in Batch at once\n",
    "    \n",
    "    M_prev: Memory Matrix at the previous time step of size (Batch_size,N,M)\n",
    "    w_t: (Batch_size,N), Weighting generated by WRITE HEAD at time t for Writing to the memory locations.\n",
    "    e_t: (Batch_size,M), Erase vector generated by WRITE HEAD.\n",
    "    a_t: (Batch_size,M), Add vector generated by WRITE HEAD.\n",
    "    \n",
    "    RETURNS:\n",
    "    \n",
    "    M_t: (Batch_size,N,M), New Memory Matrix after Erasing/Adding/Combination of new instances.\n",
    "    '''\n",
    "    \n",
    "    (batch_size,N,M) = M_prev.shape\n",
    "    \n",
    "    M_hat_t = tf.multiply( M_prev, 1-tf.multiply(tf.reshape(w_t,(batch_size,N,1)),tf.reshape(e_t,(batch_size,1,M))))\n",
    "    #^Of shape [batch_size,N,M]\n",
    "    \n",
    "    \n",
    "    assert M_hat_t.shape == M_prev.shape\n",
    "    \n",
    "    M_t = M_prev + tf.multiply(tf.reshape(w_t,(batch_size,N,1)),tf.reshape(a_t,(batch_size,1,M)))\n",
    "    \n",
    "    assert M_t.shape == M_prev.shape\n",
    "    \n",
    "    return M_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=46467, shape=(3, 2), dtype=int64, numpy=\n",
       "array([[ 1,  2],\n",
       "       [ 6,  8],\n",
       "       [15, 18]])>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(np.array([[1],[2],[3]]),np.array([[1,2],[3,4],[5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([54, 120, 1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(w_t,(batch_size,N,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([54, 1, 28])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(e_t,(batch_size,1,M)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=46512, shape=(54, 120, 28), dtype=float32, numpy=\n",
       "array([[[0.12466209, 0.01185953, 0.4066372 , ..., 0.6541431 ,\n",
       "         0.32235393, 0.59315   ],\n",
       "        [0.38001245, 0.6197917 , 0.5254241 , ..., 0.2955763 ,\n",
       "         0.611064  , 0.299763  ],\n",
       "        [0.20401934, 0.37730828, 0.7601894 , ..., 0.927123  ,\n",
       "         0.56642765, 0.46336251],\n",
       "        ...,\n",
       "        [0.7103551 , 0.2320269 , 0.621648  , ..., 0.07797381,\n",
       "         0.3594908 , 0.21159324],\n",
       "        [0.15581657, 0.6271317 , 0.5058738 , ..., 0.02510409,\n",
       "         0.98569417, 0.34371197],\n",
       "        [0.32510385, 0.41160035, 0.5350565 , ..., 0.19147713,\n",
       "         0.40304554, 0.29897645]],\n",
       "\n",
       "       [[0.2519069 , 0.08076161, 0.06650317, ..., 0.1413985 ,\n",
       "         0.51315796, 0.6752432 ],\n",
       "        [0.23208766, 0.01559431, 0.12047119, ..., 0.55408657,\n",
       "         0.68951213, 0.1678423 ],\n",
       "        [0.25133756, 0.03863765, 0.18350871, ..., 0.38185447,\n",
       "         0.07543331, 0.7184113 ],\n",
       "        ...,\n",
       "        [0.8956722 , 0.0336101 , 0.17624776, ..., 0.2684934 ,\n",
       "         0.07434992, 0.04819271],\n",
       "        [0.67668945, 0.2962125 , 0.05612803, ..., 0.4679492 ,\n",
       "         0.10547625, 0.21747799],\n",
       "        [0.29021516, 0.05765563, 0.169098  , ..., 0.28172994,\n",
       "         0.53680384, 0.01658355]],\n",
       "\n",
       "       [[0.48094442, 0.06048452, 0.5922923 , ..., 0.58301115,\n",
       "         0.22436316, 0.09137567],\n",
       "        [0.82924557, 0.00978052, 0.88150615, ..., 0.46654063,\n",
       "         0.09194811, 0.23060536],\n",
       "        [0.19261675, 0.09603286, 0.65453565, ..., 0.24345005,\n",
       "         0.15865265, 0.27283403],\n",
       "        ...,\n",
       "        [0.16315939, 0.50156856, 0.9090588 , ..., 0.29432017,\n",
       "         0.438189  , 0.33385098],\n",
       "        [0.51409924, 0.44929683, 0.82679236, ..., 0.35048643,\n",
       "         0.03302509, 0.21423627],\n",
       "        [0.8344413 , 0.7205939 , 0.161725  , ..., 0.25663564,\n",
       "         0.34643057, 0.19669013]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.18296246, 0.46424702, 0.30844384, ..., 0.39743683,\n",
       "         0.7364196 , 0.90472597],\n",
       "        [0.179992  , 0.6409753 , 0.2653564 , ..., 0.3085719 ,\n",
       "         0.83802265, 0.3173841 ],\n",
       "        [0.03731981, 0.02870617, 0.16443186, ..., 0.8066612 ,\n",
       "         0.79579884, 0.03973701],\n",
       "        ...,\n",
       "        [0.53638524, 0.71970654, 0.07665298, ..., 0.12678337,\n",
       "         0.51839787, 0.01300128],\n",
       "        [0.50750977, 0.40143746, 0.13039115, ..., 0.16510618,\n",
       "         0.54192716, 0.37816462],\n",
       "        [0.1600914 , 0.85590655, 0.04309295, ..., 0.79127765,\n",
       "         0.46278027, 0.30874288]],\n",
       "\n",
       "       [[0.22976603, 0.6072417 , 0.3176271 , ..., 0.39204708,\n",
       "         0.14518647, 0.27705154],\n",
       "        [0.11605286, 0.4410688 , 0.40945306, ..., 0.04371358,\n",
       "         0.35369793, 0.85443527],\n",
       "        [0.65522456, 0.74115306, 0.73710465, ..., 0.78416216,\n",
       "         0.17122298, 0.6756168 ],\n",
       "        ...,\n",
       "        [0.07110093, 0.7883351 , 0.44264188, ..., 0.5449828 ,\n",
       "         0.16365954, 0.31550562],\n",
       "        [0.4472256 , 0.4453999 , 0.27398935, ..., 0.41243106,\n",
       "         0.0219309 , 0.86267185],\n",
       "        [0.23001558, 0.33632666, 0.27298868, ..., 0.3560398 ,\n",
       "         0.05647124, 0.80205035]],\n",
       "\n",
       "       [[0.13923852, 0.62924224, 0.3499838 , ..., 0.9927965 ,\n",
       "         0.79512   , 0.27483794],\n",
       "        [0.3055221 , 0.67124873, 0.04827319, ..., 0.20099181,\n",
       "         0.0232607 , 0.79458135],\n",
       "        [0.47978848, 0.36823824, 0.8078221 , ..., 0.34282708,\n",
       "         0.43789476, 0.201526  ],\n",
       "        ...,\n",
       "        [0.7126182 , 0.649713  , 0.28182825, ..., 0.01247673,\n",
       "         0.19724715, 0.26899672],\n",
       "        [0.17998546, 0.7825719 , 0.24704169, ..., 0.16025467,\n",
       "         0.5429846 , 0.6303638 ],\n",
       "        [0.28446463, 0.3224923 , 0.72165394, ..., 0.20946597,\n",
       "         0.34279513, 0.11221727]]], dtype=float32)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply( M_prev, 1-tf.multiply(tf.reshape(w_t,(batch_size,N,1)),tf.reshape(e_t,(batch_size,1,M))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=46545, shape=(54, 120, 28), dtype=float32, numpy=\n",
       "array([[[0.6302588 , 0.21265168, 1.085969  , ..., 0.90555835,\n",
       "         0.74730134, 1.7050848 ],\n",
       "        [0.6483498 , 1.046634  , 0.8121977 , ..., 0.3457772 ,\n",
       "         0.80191195, 0.72178245],\n",
       "        [0.25161204, 0.42268232, 0.8271928 , ..., 0.9525206 ,\n",
       "         0.6070089 , 0.5571425 ],\n",
       "        ...,\n",
       "        [1.0095346 , 0.39979222, 0.8928581 , ..., 0.09815055,\n",
       "         0.5260487 , 0.57347494],\n",
       "        [0.30547768, 0.88500136, 0.69500446, ..., 0.03622218,\n",
       "         1.1205815 , 0.63789976],\n",
       "        [0.7252695 , 1.0276866 , 0.99679875, ..., 0.24996248,\n",
       "         0.68706787, 0.9414414 ]],\n",
       "\n",
       "       [[0.5300431 , 1.2941301 , 1.0995653 , ..., 0.80758834,\n",
       "         1.4802761 , 1.5176778 ],\n",
       "        [0.39700538, 0.5008979 , 0.7342089 , ..., 1.145437  ,\n",
       "         1.2882457 , 0.52745974],\n",
       "        [0.4561191 , 0.680219  , 1.0277897 , ..., 1.0280552 ,\n",
       "         0.6370976 , 1.329173  ],\n",
       "        ...,\n",
       "        [1.2459085 , 1.0262616 , 1.4976895 , ..., 1.1772233 ,\n",
       "         0.8502333 , 0.61405617],\n",
       "        [0.94490516, 1.6534541 , 0.8693741 , ..., 1.3440048 ,\n",
       "         0.75307274, 0.7417034 ],\n",
       "        [0.5526234 , 0.99560094, 1.3014936 , ..., 1.077555  ,\n",
       "         1.4400918 , 0.52174664]],\n",
       "\n",
       "       [[0.82775205, 0.12448707, 0.8813158 , ..., 0.78584623,\n",
       "         0.50724155, 0.37843472],\n",
       "        [1.0380573 , 0.04037085, 1.0391092 , ..., 0.5433449 ,\n",
       "         0.22452098, 0.39577925],\n",
       "        [0.8778128 , 0.25276908, 1.3109565 , ..., 0.56992567,\n",
       "         0.78990924, 1.0674822 ],\n",
       "        ...,\n",
       "        [0.75160545, 0.7428463 , 1.5089655 , ..., 0.5988451 ,\n",
       "         1.1438794 , 1.0587671 ],\n",
       "        [1.5343318 , 0.7645897 , 1.6143069 , ..., 1.0045495 ,\n",
       "         0.6756572 , 1.1195598 ],\n",
       "        [1.2297373 , 0.8553787 , 0.42548153, ..., 0.35122168,\n",
       "         0.64569837, 0.49786463]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.31422222, 0.49833703, 0.40092787, ..., 0.4989956 ,\n",
       "         0.7943827 , 1.1110901 ],\n",
       "        [0.71631324, 0.79649085, 0.63298666, ..., 0.6940011 ,\n",
       "         1.0768428 , 0.95565206],\n",
       "        [0.92666024, 0.18900152, 0.84565437, ..., 1.6055167 ,\n",
       "         1.2497444 , 1.03641   ],\n",
       "        ...,\n",
       "        [1.3783698 , 0.9010825 , 0.3956861 , ..., 0.5344294 ,\n",
       "         0.7445161 , 0.5748647 ],\n",
       "        [1.030853  , 0.49718928, 0.36222237, ..., 0.4479006 ,\n",
       "         0.69809604, 0.8683098 ],\n",
       "        [0.9246651 , 1.111374  , 0.4293578 , ..., 1.3768846 ,\n",
       "         0.7421643 , 1.2200334 ]],\n",
       "\n",
       "       [[0.8318507 , 0.86334705, 0.97663134, ..., 0.8793652 ,\n",
       "         0.32556254, 0.43782216],\n",
       "        [0.4674478 , 0.6936375 , 1.100881  , ..., 0.3313251 ,\n",
       "         0.72274   , 1.1068085 ],\n",
       "        [1.017808  , 0.8634197 , 1.1020119 , ..., 1.0718387 ,\n",
       "         0.243817  , 0.7779296 ],\n",
       "        ...,\n",
       "        [0.24598967, 1.0016189 , 1.0151061 , ..., 0.99439335,\n",
       "         0.30886596, 0.4517359 ],\n",
       "        [0.9012157 , 0.61651504, 0.70055395, ..., 0.72463906,\n",
       "         0.06461848, 1.029964  ],\n",
       "        [0.82385546, 0.5864872 , 0.91166735, ..., 0.8197569 ,\n",
       "         0.15503407, 1.0454139 ]],\n",
       "\n",
       "       [[0.29509386, 1.0923638 , 0.48138928, ..., 1.1894453 ,\n",
       "         1.0472873 , 0.52689755],\n",
       "        [0.39187104, 0.8684979 , 0.08500253, ..., 0.28453124,\n",
       "         0.04794509, 0.9030123 ],\n",
       "        [0.95186603, 0.9506088 , 1.0895677 , ..., 0.60974276,\n",
       "         0.6747397 , 0.54514694],\n",
       "        ...,\n",
       "        [0.7979417 , 0.76734734, 0.3120135 , ..., 0.06277765,\n",
       "         0.22157507, 0.3339779 ],\n",
       "        [0.1881091 , 0.8080198 , 0.2530615 , ..., 0.17079756,\n",
       "         0.5517689 , 0.64402586],\n",
       "        [0.836516  , 1.1123328 , 1.0990876 , ..., 0.5735045 ,\n",
       "         0.6453989 , 0.5808767 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_prev + tf.multiply(tf.reshape(w_t,(batch_size,N,1)),tf.reshape(a_t,(batch_size,1,M)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=46618, shape=(68, 100, 20), dtype=float32, numpy=\n",
       "array([[[0.9269947 , 0.18070653, 0.56467706, ..., 0.669017  ,\n",
       "         0.5463979 , 1.0143723 ],\n",
       "        [0.741804  , 0.4565654 , 0.70919394, ..., 1.0868827 ,\n",
       "         0.7759407 , 0.72396123],\n",
       "        [0.38641325, 0.25682545, 0.47741446, ..., 0.737785  ,\n",
       "         0.83834195, 0.7259721 ],\n",
       "        ...,\n",
       "        [0.68615866, 0.88903993, 0.25532448, ..., 0.45391294,\n",
       "         0.5564223 , 0.6809142 ],\n",
       "        [0.23190612, 0.13355017, 0.56690216, ..., 1.0081687 ,\n",
       "         0.5462    , 0.7016797 ],\n",
       "        [0.24384663, 0.4104563 , 0.44970807, ..., 0.54653764,\n",
       "         0.64238185, 0.39973623]],\n",
       "\n",
       "       [[1.564601  , 0.6283729 , 0.7955998 , ..., 1.1825564 ,\n",
       "         1.0247817 , 1.2223755 ],\n",
       "        [0.82689345, 1.4993862 , 1.3725848 , ..., 1.5167229 ,\n",
       "         0.7009622 , 0.4465777 ],\n",
       "        [1.8378738 , 1.0191371 , 0.8405704 , ..., 1.2319281 ,\n",
       "         1.6295192 , 0.5357495 ],\n",
       "        ...,\n",
       "        [1.733243  , 1.2638831 , 1.0667794 , ..., 0.8714281 ,\n",
       "         0.82282436, 0.938162  ],\n",
       "        [1.4651959 , 1.6319249 , 0.7893365 , ..., 1.2588876 ,\n",
       "         1.0228493 , 0.37500197],\n",
       "        [1.1142497 , 0.6172083 , 0.49448508, ..., 1.2220776 ,\n",
       "         0.6176148 , 0.6960039 ]],\n",
       "\n",
       "       [[0.79819775, 0.77692   , 1.3826042 , ..., 1.1394484 ,\n",
       "         0.96962166, 1.0313419 ],\n",
       "        [0.6141336 , 0.6578589 , 0.26257473, ..., 0.43302858,\n",
       "         0.17437987, 0.85529983],\n",
       "        [0.6082348 , 0.7056594 , 0.7221523 , ..., 0.30390862,\n",
       "         0.31816748, 0.3181538 ],\n",
       "        ...,\n",
       "        [0.55583787, 0.7681341 , 0.84933585, ..., 0.0406137 ,\n",
       "         0.67707676, 0.3905744 ],\n",
       "        [1.0202018 , 0.4886766 , 0.4762284 , ..., 1.002447  ,\n",
       "         0.6596106 , 1.5382497 ],\n",
       "        [0.5814018 , 0.66954577, 0.95855844, ..., 0.4703243 ,\n",
       "         0.44492957, 1.364245  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.5878155 , 0.32344717, 0.40345   , ..., 1.6013869 ,\n",
       "         1.1460251 , 0.90600663],\n",
       "        [0.7806861 , 0.8792674 , 0.7811249 , ..., 0.8917294 ,\n",
       "         0.83896196, 0.56252074],\n",
       "        [1.2919662 , 0.9698177 , 0.62983745, ..., 1.1301432 ,\n",
       "         1.2449466 , 0.94194895],\n",
       "        ...,\n",
       "        [0.17203088, 0.77698827, 0.4192505 , ..., 0.70115036,\n",
       "         0.19454995, 0.9836396 ],\n",
       "        [0.5337511 , 0.76419854, 0.9849176 , ..., 0.853077  ,\n",
       "         1.1715275 , 1.3131174 ],\n",
       "        [1.0975488 , 0.37814713, 0.38050792, ..., 1.0328803 ,\n",
       "         0.525607  , 1.0653901 ]],\n",
       "\n",
       "       [[0.52934426, 0.91188425, 0.5566034 , ..., 0.8178828 ,\n",
       "         0.13897768, 0.64898014],\n",
       "        [0.51710624, 0.4220546 , 0.56000096, ..., 0.29762003,\n",
       "         0.8956014 , 1.0189105 ],\n",
       "        [0.57780945, 1.4159143 , 0.81715024, ..., 1.0710005 ,\n",
       "         0.63586986, 1.0496593 ],\n",
       "        ...,\n",
       "        [0.71406424, 0.58074534, 0.7748108 , ..., 0.24253573,\n",
       "         0.06262335, 0.27785766],\n",
       "        [1.2035937 , 0.5874914 , 0.92579794, ..., 0.69161063,\n",
       "         0.6172014 , 0.98617756],\n",
       "        [1.3312407 , 1.2448542 , 0.8163222 , ..., 0.37202322,\n",
       "         0.24684641, 1.0168893 ]],\n",
       "\n",
       "       [[1.4242374 , 0.274087  , 0.8512447 , ..., 0.6598406 ,\n",
       "         1.0902336 , 1.1187292 ],\n",
       "        [1.1280178 , 0.65423757, 0.07499149, ..., 0.29310042,\n",
       "         1.0300585 , 1.1684606 ],\n",
       "        [1.3488531 , 0.3790074 , 0.2360884 , ..., 0.68734837,\n",
       "         1.3195071 , 1.3924191 ],\n",
       "        ...,\n",
       "        [1.1759336 , 0.7461322 , 0.6505524 , ..., 0.43426403,\n",
       "         1.2695107 , 0.8624094 ],\n",
       "        [0.7133559 , 1.0754002 , 1.0036907 , ..., 0.5602375 ,\n",
       "         0.82186043, 1.2722626 ],\n",
       "        [0.36185846, 0.80082273, 0.29416713, ..., 0.6386157 ,\n",
       "         0.76383674, 0.83572876]]], dtype=float32)>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WriteOnMemory(M_prev, w_t, e_t, a_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
