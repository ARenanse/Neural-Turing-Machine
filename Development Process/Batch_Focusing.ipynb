{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Focusing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ContentFocusing(k_t, M_prev, beta_t, K = None):\n",
    "    \n",
    "    '''\n",
    "    Computes the Write Vector for whole batch through Content Attentioning in one go.\n",
    "    \n",
    "    k_t : (Batch_size,M), Key Vector generated by EITHER HEAD (in whichever HEAD this function is used in for addressing)\n",
    "    M_prev : (Batch_size,N,M), Memory Matrix at time t.\n",
    "    beta_t : (Batch_size,1), Key Strength hyperparameter\n",
    "    K : Function, Similarity Measure, if None, Cosine Similarity will be used.\n",
    "    \n",
    "    RETURNS:\n",
    "    \n",
    "    w_ct : (Batch_size,N), Weighting after Content Focusing. \n",
    "    '''\n",
    "    \n",
    "    batch_size,N,M = M_prev.shape\n",
    "    \n",
    "\n",
    "    \n",
    "    if K != None : \n",
    "            \n",
    "        K_kt_Mprev = K(k_t,M_prev)\n",
    "    \n",
    "    else:\n",
    "        K_kt_Mprev = tf.reduce_sum(tf.reshape(k_t,(batch_size,1,M))*M_prev, axis = 2) /  tf.multiply(tf.reshape(tf.linalg.norm(k_t,axis =1),(batch_size,1)),tf.linalg.norm(M_prev,axis = 2)) \n",
    "        #^ Of shape [batch_size, N]\n",
    "    exp_vals = tf.exp(beta_t*K_kt_Mprev)\n",
    "    w_ct = exp_vals / tf.reshape(tf.reduce_sum(exp_vals,axis = 1),(-1,1)) \n",
    "    \n",
    "    assert w_ct.shape == (batch_size,N)\n",
    "    \n",
    "    return w_ct\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 61\n",
    "features = 10\n",
    "inputs = tf.random.uniform((batch_size,features))\n",
    "n_RH = 1\n",
    "n_WH = 2\n",
    "N = 90\n",
    "M = 10\n",
    "M_prev = tf.random.uniform((batch_size,N,M))\n",
    "w_t = tf.random.uniform((batch_size,N))\n",
    "a_t = tf.random.uniform((batch_size,M))\n",
    "e_t = tf.random.uniform((batch_size,M))\n",
    "k_t = tf.random.uniform((batch_size,M))\n",
    "beta_t = tf.random.uniform((batch_size,1))\n",
    "w_prev = tf.random.uniform((batch_size,N))\n",
    "g_t = tf.random.uniform((batch_size,1))\n",
    "s_t = tf.random.uniform((batch_size,3)) #let len(shift_range = 3)\n",
    "gamma_t = tf.random.uniform((batch_size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=78, shape=(90, 10), dtype=float32, numpy=\n",
       "array([[2.05493674e-01, 4.30796772e-01, 8.00636530e-01, 2.90890127e-01,\n",
       "        2.03438140e-02, 2.84723818e-01, 5.93787171e-02, 2.68620905e-02,\n",
       "        6.08717464e-03, 4.67993557e-01],\n",
       "       [3.08563024e-01, 6.22952104e-01, 7.58889139e-01, 7.00889945e-01,\n",
       "        1.17800213e-01, 2.61898994e-01, 1.19392000e-01, 4.17016819e-02,\n",
       "        5.51945472e-04, 3.33412975e-01],\n",
       "       [2.39747286e-01, 3.85779083e-01, 5.71780741e-01, 4.23119813e-01,\n",
       "        1.22678958e-01, 1.49898782e-01, 2.11717144e-01, 1.55228311e-02,\n",
       "        2.56567192e-03, 2.37495601e-01],\n",
       "       [1.07483469e-01, 2.44085670e-01, 2.66609997e-01, 6.59644008e-01,\n",
       "        9.81792659e-02, 3.70828599e-01, 1.59274265e-01, 4.75123860e-02,\n",
       "        6.68983033e-04, 3.83947700e-01],\n",
       "       [2.50789434e-01, 6.78528070e-01, 8.51687312e-01, 3.63416970e-02,\n",
       "        1.65671006e-01, 3.57668638e-01, 1.20984100e-01, 2.11320650e-02,\n",
       "        3.30919935e-03, 7.62967467e-02],\n",
       "       [6.71993494e-02, 3.78019780e-01, 9.16909218e-01, 5.45125902e-01,\n",
       "        5.45569770e-02, 1.87302325e-02, 1.70496630e-03, 2.39143129e-02,\n",
       "        4.01715189e-03, 2.56531179e-01],\n",
       "       [2.27173507e-01, 5.54699041e-02, 1.32003412e-01, 7.46313512e-01,\n",
       "        4.71603684e-02, 5.32806814e-02, 8.08544010e-02, 3.76780815e-02,\n",
       "        4.78632050e-03, 1.63950324e-01],\n",
       "       [1.95853591e-01, 2.76992600e-02, 4.73172903e-01, 5.69131911e-01,\n",
       "        1.47568703e-01, 3.69290233e-01, 4.08600830e-02, 6.67038467e-03,\n",
       "        5.17741684e-03, 4.65338677e-01],\n",
       "       [1.64828956e-01, 2.28992682e-02, 2.32397527e-01, 8.19423735e-01,\n",
       "        1.62994951e-01, 2.16842115e-01, 2.20309794e-02, 5.97227663e-02,\n",
       "        3.30253126e-04, 3.99517566e-01],\n",
       "       [2.59716570e-01, 4.37206417e-01, 3.09642971e-01, 7.26422191e-01,\n",
       "        9.67133492e-02, 2.46578947e-01, 4.70078111e-01, 4.44518737e-02,\n",
       "        4.21363767e-03, 4.81319986e-02],\n",
       "       [1.34752989e-01, 4.37200665e-01, 3.57129306e-01, 2.88034584e-02,\n",
       "        1.32801101e-01, 3.63788784e-01, 6.55260682e-02, 1.00647202e-02,\n",
       "        3.28505854e-03, 4.49868113e-01],\n",
       "       [2.85864621e-01, 8.14267471e-02, 2.24621937e-01, 5.76667011e-01,\n",
       "        1.53132528e-01, 2.74247020e-01, 1.48322666e-02, 4.05068770e-02,\n",
       "        5.51839033e-03, 3.12829405e-01],\n",
       "       [1.30803287e-01, 3.25354338e-01, 4.74351048e-01, 5.99378161e-02,\n",
       "        8.81112069e-02, 2.56317914e-01, 4.04906690e-01, 1.30995521e-02,\n",
       "        6.17830665e-04, 4.37084347e-01],\n",
       "       [6.54106438e-02, 2.95703802e-02, 2.33579218e-01, 2.77601957e-01,\n",
       "        1.37335330e-01, 2.36034200e-01, 8.18916410e-02, 5.21997176e-02,\n",
       "        3.66772315e-03, 3.50062698e-01],\n",
       "       [1.61218613e-01, 6.56205118e-01, 7.98018813e-01, 6.66900814e-01,\n",
       "        7.57661164e-02, 3.90727907e-01, 4.03896958e-01, 2.32355818e-02,\n",
       "        2.88508047e-04, 1.09619111e-01],\n",
       "       [1.19854519e-02, 6.32666588e-01, 2.05758333e-01, 4.93686855e-01,\n",
       "        6.52594417e-02, 9.08815563e-02, 8.39498173e-03, 3.47325057e-02,\n",
       "        6.09863596e-03, 2.64845401e-01],\n",
       "       [2.16411993e-01, 6.05796456e-01, 6.61863983e-01, 5.80801606e-01,\n",
       "        8.41292888e-02, 2.53722578e-01, 4.69138354e-01, 2.28790212e-02,\n",
       "        4.96491324e-03, 9.87369269e-02],\n",
       "       [1.18357137e-01, 1.32719740e-01, 5.04210353e-01, 6.86721981e-01,\n",
       "        6.01521395e-02, 1.95725292e-01, 3.01095806e-02, 1.03175247e-04,\n",
       "        3.78573569e-03, 3.46995294e-01],\n",
       "       [1.12082317e-01, 5.82122445e-01, 7.77995348e-01, 5.30597866e-01,\n",
       "        1.15125358e-01, 2.03688726e-01, 5.53760957e-03, 3.20006208e-03,\n",
       "        6.99083786e-04, 4.80115056e-01],\n",
       "       [9.69229341e-02, 4.04260933e-01, 7.33239233e-01, 4.45956916e-01,\n",
       "        9.50415805e-03, 8.16945881e-02, 2.86794573e-01, 2.93017086e-03,\n",
       "        6.08126353e-03, 1.76759094e-01],\n",
       "       [9.91830379e-02, 1.40404940e-01, 9.10205022e-02, 4.12354827e-01,\n",
       "        4.28376645e-02, 1.38024762e-01, 5.02532065e-01, 1.68172400e-02,\n",
       "        3.22519592e-03, 8.35550353e-02],\n",
       "       [6.41481951e-02, 1.66842088e-01, 6.47004128e-01, 1.49548173e-01,\n",
       "        6.08462393e-02, 2.32359052e-01, 6.99381456e-02, 3.77184749e-02,\n",
       "        5.05733490e-03, 1.82606056e-01],\n",
       "       [1.05877556e-01, 5.73512614e-01, 9.11082685e-01, 7.95235157e-01,\n",
       "        4.67544049e-02, 2.10390106e-01, 5.16706407e-01, 1.53657189e-02,\n",
       "        4.69169021e-03, 1.00880213e-01],\n",
       "       [2.85026729e-01, 3.62262040e-01, 7.80800700e-01, 7.82192647e-01,\n",
       "        6.23742826e-02, 8.01023096e-03, 2.86025733e-01, 2.91527212e-02,\n",
       "        8.32406571e-04, 2.83317804e-01],\n",
       "       [1.90098032e-01, 1.02558896e-01, 7.36062944e-01, 1.89692780e-01,\n",
       "        3.82408798e-02, 3.95169705e-02, 2.00580016e-01, 5.90282120e-02,\n",
       "        5.92547143e-03, 1.15085334e-01],\n",
       "       [1.17480129e-01, 2.29153693e-01, 3.79272401e-02, 3.82820696e-01,\n",
       "        8.86292532e-02, 7.69183934e-02, 1.23757981e-01, 6.14815280e-02,\n",
       "        3.83700384e-03, 1.45183019e-02],\n",
       "       [2.15516388e-01, 8.72974038e-01, 6.74756587e-01, 6.24412954e-01,\n",
       "        1.16951697e-01, 1.88812897e-01, 4.88233954e-01, 5.33853397e-02,\n",
       "        2.43865768e-03, 4.05407101e-01],\n",
       "       [2.09311116e-02, 6.76183105e-01, 6.65458024e-01, 7.42180288e-01,\n",
       "        1.23902708e-01, 3.22726518e-01, 3.40520948e-01, 5.75715154e-02,\n",
       "        1.88073830e-03, 1.17038012e-01],\n",
       "       [2.80839562e-01, 6.89143360e-01, 1.70159981e-01, 7.41013512e-02,\n",
       "        1.58007052e-02, 2.96676010e-01, 3.82196099e-01, 2.28918605e-02,\n",
       "        5.30042592e-03, 4.02832419e-01],\n",
       "       [1.31920621e-01, 6.58238351e-01, 1.66777790e-01, 7.45819807e-01,\n",
       "        1.09129362e-01, 3.56449783e-01, 5.05488396e-01, 5.11657111e-02,\n",
       "        1.87605008e-04, 2.42011100e-02],\n",
       "       [2.76355535e-01, 4.49960470e-01, 1.74567811e-02, 4.98803735e-01,\n",
       "        9.77777988e-02, 3.17055047e-01, 5.43740690e-02, 3.78405191e-02,\n",
       "        4.24804632e-03, 4.14518654e-01],\n",
       "       [7.75256604e-02, 7.34736085e-01, 6.58070207e-01, 3.09626788e-01,\n",
       "        6.17165528e-02, 1.98700771e-01, 2.43408874e-01, 4.46870625e-02,\n",
       "        5.04142558e-03, 2.66044080e-01],\n",
       "       [2.55960912e-01, 3.78500313e-01, 6.65264487e-01, 6.12848580e-01,\n",
       "        1.03626862e-01, 1.44519329e-01, 1.45477936e-01, 6.25374541e-02,\n",
       "        4.18647425e-03, 3.07624519e-01],\n",
       "       [2.70404786e-01, 8.31202883e-03, 8.19718778e-01, 5.85865021e-01,\n",
       "        1.76563878e-02, 8.62566233e-02, 4.76326376e-01, 3.66915837e-02,\n",
       "        4.59758984e-03, 1.72682405e-01],\n",
       "       [1.20131180e-01, 1.93865955e-01, 4.55121249e-01, 1.29626751e-01,\n",
       "        8.73317719e-02, 3.47516388e-01, 1.18897490e-01, 2.52315030e-02,\n",
       "        1.32025254e-03, 2.33001962e-01],\n",
       "       [1.53322434e-02, 5.59655547e-01, 5.47863662e-01, 6.63837075e-01,\n",
       "        1.45913810e-01, 2.22803399e-01, 6.16160221e-02, 1.79146603e-02,\n",
       "        1.35190121e-03, 2.76126921e-01],\n",
       "       [1.31522799e-02, 3.91010076e-01, 7.57151842e-01, 3.57487082e-01,\n",
       "        1.27556786e-01, 3.36810142e-01, 4.60375488e-01, 2.52481904e-02,\n",
       "        2.74967658e-03, 4.02595162e-01],\n",
       "       [2.74933994e-01, 3.91121089e-01, 5.56688786e-01, 7.83549786e-01,\n",
       "        1.15825295e-01, 1.38943583e-01, 2.84791708e-01, 3.13385837e-02,\n",
       "        2.70499149e-04, 2.15705529e-01],\n",
       "       [1.17004842e-01, 1.54588670e-01, 7.61539519e-01, 3.77610505e-01,\n",
       "        8.64252448e-02, 3.34368616e-01, 5.07497907e-01, 5.04249707e-02,\n",
       "        9.54239367e-05, 3.46737742e-01],\n",
       "       [1.50535375e-01, 8.05458844e-01, 3.24258208e-01, 2.62198418e-01,\n",
       "        4.77839634e-02, 9.89081264e-02, 7.01398589e-03, 2.55937446e-02,\n",
       "        6.78540266e-04, 9.47335437e-02],\n",
       "       [6.93072751e-02, 5.07943928e-01, 2.74143368e-01, 4.05624360e-01,\n",
       "        2.02761800e-03, 4.01195765e-01, 4.22875196e-01, 5.53916097e-02,\n",
       "        5.71959885e-03, 1.29323259e-01],\n",
       "       [3.09976727e-01, 1.12978607e-01, 4.42863226e-01, 6.56209409e-01,\n",
       "        1.37616262e-01, 2.27219835e-01, 2.32871398e-01, 2.28768494e-02,\n",
       "        5.87326661e-03, 5.49287200e-02],\n",
       "       [1.69951960e-01, 2.69794494e-01, 5.19480050e-01, 6.84841424e-02,\n",
       "        9.75735262e-02, 1.63039297e-01, 3.74838918e-01, 3.19717787e-02,\n",
       "        3.26432590e-03, 1.03336506e-01],\n",
       "       [1.19603567e-01, 2.76658714e-01, 1.31339446e-01, 2.36829102e-01,\n",
       "        6.88393638e-02, 1.68141693e-01, 6.96054697e-02, 4.32787389e-02,\n",
       "        4.19932138e-03, 4.34831113e-01],\n",
       "       [2.00118661e-01, 5.37912428e-01, 6.69128716e-01, 4.34111148e-01,\n",
       "        8.05187002e-02, 1.28844857e-01, 4.74820323e-02, 5.94309941e-02,\n",
       "        1.92244421e-04, 2.19733641e-01],\n",
       "       [1.30540892e-01, 3.03406626e-01, 7.88966835e-01, 6.23114944e-01,\n",
       "        2.39052568e-02, 6.71747327e-02, 4.28402781e-01, 6.01547137e-02,\n",
       "        4.63348115e-03, 2.53332764e-01],\n",
       "       [1.28500462e-01, 8.62292349e-02, 5.85673094e-01, 6.06191993e-01,\n",
       "        1.32256284e-01, 2.71965146e-01, 9.16636959e-02, 2.95094028e-02,\n",
       "        1.44041190e-03, 2.13819325e-01],\n",
       "       [4.03484795e-03, 3.55944306e-01, 3.06573421e-01, 2.65995353e-01,\n",
       "        1.13313809e-01, 3.78214449e-01, 4.98374291e-02, 2.45679133e-02,\n",
       "        2.07335412e-04, 1.17264576e-02],\n",
       "       [1.29053921e-01, 6.71240747e-01, 8.37465167e-01, 7.30885208e-01,\n",
       "        1.23053916e-01, 1.86096713e-01, 3.43950301e-01, 4.49676886e-02,\n",
       "        6.14818279e-03, 3.41954678e-01],\n",
       "       [1.98178396e-01, 5.14199138e-01, 7.55537271e-01, 5.08422315e-01,\n",
       "        3.77438404e-03, 2.68756300e-01, 4.88785893e-01, 1.03786886e-02,\n",
       "        4.99642501e-03, 3.61471087e-01],\n",
       "       [1.73664063e-01, 6.42212152e-01, 1.07645482e-01, 5.13326347e-01,\n",
       "        1.12510629e-01, 1.17887087e-01, 2.77416229e-01, 2.45960820e-02,\n",
       "        4.83998423e-03, 1.69743314e-01],\n",
       "       [2.71649867e-01, 3.63724858e-01, 2.27065876e-01, 4.93443370e-01,\n",
       "        6.75254464e-02, 5.81617933e-03, 2.81023413e-01, 5.40174283e-02,\n",
       "        4.54478152e-03, 2.85998762e-01],\n",
       "       [7.53915459e-02, 6.92945957e-01, 9.17326033e-01, 2.12402064e-02,\n",
       "        8.11131895e-02, 3.13867658e-01, 1.48062229e-01, 3.69258076e-02,\n",
       "        3.17792292e-03, 1.31217957e-01],\n",
       "       [2.52412679e-03, 3.47534746e-01, 6.85440063e-01, 3.35075766e-01,\n",
       "        1.67606305e-03, 1.98225588e-01, 4.51606631e-01, 4.83923443e-02,\n",
       "        4.87448135e-03, 4.69228446e-01],\n",
       "       [1.84100538e-01, 3.21895450e-01, 3.27187687e-01, 5.48239686e-02,\n",
       "        5.78473695e-03, 2.98016608e-01, 3.29985529e-01, 1.69802904e-02,\n",
       "        2.73438916e-03, 5.41201280e-03],\n",
       "       [2.51283823e-03, 2.87693050e-02, 5.13786614e-01, 6.85270429e-01,\n",
       "        1.15391158e-01, 2.63428181e-01, 4.06787664e-01, 4.43798825e-02,\n",
       "        6.10922324e-03, 3.94542515e-01],\n",
       "       [2.99805105e-01, 4.99085546e-01, 7.55352139e-01, 6.35553062e-01,\n",
       "        2.55310703e-02, 1.52127549e-01, 4.04717922e-01, 4.29355958e-03,\n",
       "        5.07907942e-03, 1.60488170e-02],\n",
       "       [2.91027188e-01, 7.18612492e-01, 8.26668620e-01, 2.13844940e-01,\n",
       "        6.79513887e-02, 2.19606400e-01, 2.30641499e-01, 1.37760034e-02,\n",
       "        1.85939716e-03, 1.46315871e-02],\n",
       "       [2.75711000e-01, 5.47317207e-01, 1.09657981e-01, 7.34474063e-02,\n",
       "        1.31831393e-01, 1.05514675e-01, 4.74053681e-01, 3.17768194e-02,\n",
       "        1.17806310e-03, 2.22570330e-01],\n",
       "       [3.03657092e-02, 3.79591086e-03, 4.84762676e-02, 7.72302091e-01,\n",
       "        1.44275054e-01, 2.48112425e-01, 9.39095914e-02, 5.74392732e-04,\n",
       "        2.61919573e-03, 3.16673547e-01],\n",
       "       [4.28846702e-02, 7.08266556e-01, 6.71827346e-02, 2.71343648e-01,\n",
       "        1.03041455e-01, 3.94615233e-01, 3.98356736e-01, 3.16312793e-03,\n",
       "        6.09608740e-03, 1.66977853e-01],\n",
       "       [1.03821024e-01, 3.75863552e-01, 5.96345782e-01, 7.67146766e-01,\n",
       "        3.49107310e-02, 1.65910959e-01, 3.00290763e-01, 5.90396039e-02,\n",
       "        1.67292950e-03, 1.98337734e-01],\n",
       "       [5.07759228e-02, 7.32827544e-01, 1.58654511e-01, 1.04206920e-01,\n",
       "        3.63319777e-02, 1.72440976e-01, 5.05497456e-01, 2.75779795e-02,\n",
       "        4.83883807e-04, 1.69793680e-01],\n",
       "       [2.35577703e-01, 7.93530285e-01, 1.43769830e-01, 2.07078665e-01,\n",
       "        1.05558515e-01, 2.79303730e-01, 5.14030993e-01, 1.47613548e-02,\n",
       "        3.59284505e-03, 1.67034581e-01],\n",
       "       [1.00951031e-01, 8.60703528e-01, 2.26959646e-01, 5.50377309e-01,\n",
       "        9.74931419e-02, 1.41499370e-01, 3.70225757e-01, 6.17523268e-02,\n",
       "        1.31049298e-03, 2.01679602e-01],\n",
       "       [2.52881318e-01, 5.65826118e-01, 3.99034798e-01, 5.16813636e-01,\n",
       "        8.80026892e-02, 1.56921268e-01, 1.18300378e-01, 2.35301182e-02,\n",
       "        5.51834237e-03, 4.30728316e-01],\n",
       "       [1.34986162e-01, 7.81329155e-01, 3.41014653e-01, 7.05862224e-01,\n",
       "        1.01441823e-01, 1.66467205e-02, 3.83625388e-01, 6.61784271e-03,\n",
       "        4.47177701e-03, 2.42709905e-01],\n",
       "       [1.46524802e-01, 7.80837595e-01, 8.01170468e-01, 1.39748588e-01,\n",
       "        7.56058618e-02, 1.37425303e-01, 5.19899726e-01, 6.24258220e-02,\n",
       "        4.87793190e-03, 1.23553500e-01],\n",
       "       [2.36239079e-02, 5.23187518e-01, 3.04188882e-03, 1.53231397e-01,\n",
       "        1.28400683e-01, 1.78559050e-01, 3.80489320e-01, 4.67074253e-02,\n",
       "        2.00640410e-03, 2.19886273e-01],\n",
       "       [2.89295048e-01, 5.15038788e-01, 1.46505684e-01, 1.57910466e-01,\n",
       "        3.84882726e-02, 1.28397513e-02, 3.57978135e-01, 2.03488264e-02,\n",
       "        1.43673480e-03, 3.24367434e-02],\n",
       "       [1.26631960e-01, 5.63490987e-01, 6.82898939e-01, 3.95059973e-01,\n",
       "        9.11230594e-02, 1.09360935e-02, 4.66208816e-01, 5.66383898e-02,\n",
       "        1.90476025e-03, 1.56831697e-01],\n",
       "       [2.83017069e-01, 5.24507642e-01, 2.80549347e-01, 5.05429566e-01,\n",
       "        1.27248093e-01, 2.67310739e-01, 4.66986597e-01, 3.48360874e-02,\n",
       "        4.73078340e-03, 4.66235042e-01],\n",
       "       [2.95813203e-01, 5.75091481e-01, 2.03974053e-01, 2.03208357e-01,\n",
       "        9.21660885e-02, 4.07715231e-01, 3.39381248e-01, 2.28872597e-02,\n",
       "        4.04710416e-03, 4.25742179e-01],\n",
       "       [2.87949681e-01, 8.78635868e-02, 1.14029776e-02, 6.89460993e-01,\n",
       "        8.22138488e-02, 1.49916604e-01, 2.68986970e-01, 4.27659974e-02,\n",
       "        4.94519295e-03, 4.57137465e-01],\n",
       "       [6.49928898e-02, 3.21382910e-01, 5.06710470e-01, 8.28107297e-02,\n",
       "        1.45175651e-01, 1.05903611e-01, 7.04811886e-02, 3.71010862e-02,\n",
       "        5.31804282e-03, 8.37083533e-02],\n",
       "       [1.12198614e-01, 8.65968406e-01, 5.92837274e-01, 6.40923560e-01,\n",
       "        1.56523511e-01, 1.63947657e-01, 4.44724172e-01, 4.46051024e-02,\n",
       "        1.68750796e-03, 1.86769649e-01],\n",
       "       [2.24196054e-02, 6.72578812e-01, 2.12072209e-01, 7.81628847e-01,\n",
       "        2.70492546e-02, 2.53376603e-01, 3.64246815e-01, 2.77208202e-02,\n",
       "        4.84889373e-03, 2.72394828e-02],\n",
       "       [4.88365851e-02, 8.12455535e-01, 4.15731966e-01, 1.97449788e-01,\n",
       "        1.19160198e-01, 2.65895844e-01, 9.80932731e-04, 1.44321853e-02,\n",
       "        3.62197077e-03, 3.09610963e-01],\n",
       "       [4.02676351e-02, 9.56805050e-02, 3.80788088e-01, 5.75193703e-01,\n",
       "        1.56401858e-01, 3.67391706e-02, 1.16180547e-01, 4.24049199e-02,\n",
       "        4.19104705e-03, 1.22656114e-01],\n",
       "       [3.19234222e-01, 7.36599624e-01, 7.70987809e-01, 1.60625726e-01,\n",
       "        1.05659686e-01, 1.22651882e-01, 4.89911735e-01, 6.03853539e-02,\n",
       "        3.59608699e-03, 4.37982142e-01],\n",
       "       [3.96952555e-02, 2.68287789e-02, 6.82370961e-01, 4.84066814e-01,\n",
       "        6.25177845e-02, 1.44738331e-01, 2.73513734e-01, 5.32739200e-02,\n",
       "        8.25225143e-04, 2.96021938e-01],\n",
       "       [7.36086220e-02, 7.94714928e-01, 5.28286815e-01, 9.67014432e-02,\n",
       "        1.37964144e-01, 3.63661498e-01, 1.59591198e-01, 3.32174562e-02,\n",
       "        4.49699629e-03, 3.48968804e-02],\n",
       "       [2.33728841e-01, 3.29407841e-01, 3.86221588e-01, 8.18786025e-01,\n",
       "        1.12572685e-01, 3.11460435e-01, 7.60005042e-02, 4.20053378e-02,\n",
       "        5.03689097e-03, 4.73451972e-01],\n",
       "       [1.36002526e-01, 4.40344006e-01, 6.42745614e-01, 2.60158390e-01,\n",
       "        9.81714055e-02, 4.11415964e-01, 1.69123724e-01, 4.76210527e-02,\n",
       "        3.24181351e-03, 2.20674157e-01],\n",
       "       [1.31988809e-01, 1.94498107e-01, 2.20103577e-01, 7.85253108e-01,\n",
       "        6.29939809e-02, 9.51452479e-02, 4.68028635e-01, 3.32199410e-02,\n",
       "        6.09789742e-03, 1.36481121e-01],\n",
       "       [2.18497872e-01, 6.74508810e-01, 5.85876048e-01, 8.10409427e-01,\n",
       "        1.27498833e-02, 2.64332086e-01, 1.94902912e-01, 3.75434868e-02,\n",
       "        4.38027404e-04, 3.39821607e-01],\n",
       "       [4.36869310e-03, 2.05860928e-01, 7.85357893e-01, 4.26892221e-01,\n",
       "        7.36280382e-02, 1.80183277e-01, 7.22864494e-02, 3.39294635e-02,\n",
       "        1.80604402e-03, 3.56567979e-01],\n",
       "       [2.12458298e-01, 6.79040968e-01, 1.83727086e-01, 4.19556856e-01,\n",
       "        4.81572188e-02, 2.70432413e-01, 4.75126565e-01, 2.37657391e-02,\n",
       "        1.49068830e-03, 1.54213548e-01],\n",
       "       [1.67255640e-01, 7.38822639e-01, 1.60260469e-01, 4.45992142e-01,\n",
       "        9.09501389e-02, 2.46971294e-01, 2.73666590e-01, 4.45398577e-02,\n",
       "        3.51586426e-03, 2.13013843e-01],\n",
       "       [2.47041017e-01, 5.74276268e-01, 5.53634346e-01, 4.61896211e-01,\n",
       "        5.45857847e-02, 3.21924806e-01, 3.86184901e-01, 4.51247804e-02,\n",
       "        3.75367323e-04, 2.09103882e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(k_t[0],M_prev[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=82, shape=(10,), dtype=float32, numpy=\n",
       "array([0.32541203, 0.87419105, 0.9244362 , 0.82293713, 0.16608787,\n",
       "       0.41414547, 0.5219244 , 0.06328118, 0.00619519, 0.48116386],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=86, shape=(10,), dtype=float32, numpy=\n",
       "array([0.6314876 , 0.49279475, 0.8660809 , 0.35347795, 0.12248826,\n",
       "       0.68749714, 0.11376882, 0.42448783, 0.98256505, 0.97262824],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_prev[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([tf.reduce_sum(tf.multiply(k_t[i],M_prev[i]), axis = 1) for i in range(batch_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 90)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.linalg.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.linalg.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.linalg.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22722, shape=(61, 90), dtype=float32, numpy=\n",
       "array([[2.027041 , 2.1642258, 1.6434479, ..., 1.723338 , 1.8016926,\n",
       "        1.9084893],\n",
       "       [1.9956269, 1.5014703, 1.7618327, ..., 2.1334832, 1.6714257,\n",
       "        1.5563629],\n",
       "       [1.4762534, 1.9331743, 1.9384431, ..., 1.8611721, 1.3271677,\n",
       "        2.3665528],\n",
       "       ...,\n",
       "       [1.8282665, 1.8271585, 1.8608762, ..., 2.1229274, 1.3248271,\n",
       "        2.0175529],\n",
       "       [1.7941804, 1.4642141, 1.7083813, ..., 2.0990129, 2.5573628,\n",
       "        2.1121614],\n",
       "       [1.7976902, 1.6338319, 1.7932703, ..., 2.1311028, 1.9314992,\n",
       "        1.5543519]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.linalg.norm(M_prev,axis = 2)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22727, shape=(61,), dtype=float32, numpy=\n",
       "array([1.7632298, 2.3290856, 1.5850703, 1.7012767, 1.7760475, 2.0075939,\n",
       "       2.1443708, 2.1399894, 2.07307  , 1.92934  , 1.5302684, 1.6068015,\n",
       "       1.6128647, 2.058905 , 1.7653611, 1.7906436, 1.747843 , 2.129794 ,\n",
       "       1.2911484, 1.3325299, 2.0616665, 1.939443 , 1.7552632, 1.6806258,\n",
       "       2.0048482, 1.9816246, 2.1701431, 1.4865725, 1.7067194, 1.5858262,\n",
       "       2.0027452, 1.5277145, 1.837927 , 2.0219283, 2.1345253, 2.025736 ,\n",
       "       2.3264446, 1.796912 , 1.6987953, 1.8551291, 2.0930135, 1.9070629,\n",
       "       1.8816838, 2.0237234, 1.5859659, 1.9742703, 1.7763777, 1.4644916,\n",
       "       1.278213 , 2.1491597, 1.7826204, 1.724457 , 1.7122903, 2.0279088,\n",
       "       1.9660336, 2.1259933, 1.7772762, 1.4175928, 2.370463 , 1.4534798,\n",
       "       2.1097548], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = tf.linalg.norm(k_t,axis =1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22740, shape=(61, 90), dtype=float32, numpy=\n",
       "array([[3.574139 , 3.8160276, 2.8977764, ..., 3.038641 , 3.176798 ,\n",
       "        3.3651054],\n",
       "       [4.647986 , 3.497053 , 4.1034594, ..., 4.9690647, 3.8928936,\n",
       "        3.6249022],\n",
       "       [2.3399653, 3.064217 , 3.0725684, ..., 2.9500885, 2.1036541,\n",
       "        3.7511525],\n",
       "       ...,\n",
       "       [4.333838 , 4.331211 , 4.411138 , ..., 5.0323205, 3.1404533,\n",
       "        4.782534 ],\n",
       "       [2.607805 , 2.1282055, 2.4830976, ..., 3.0508728, 3.717075 ,\n",
       "        3.069984 ],\n",
       "       [3.7926855, 3.4469845, 3.7833607, ..., 4.4961042, 4.07499  ,\n",
       "        3.2793014]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(tf.reshape(tf.linalg.norm(k_t,axis =1),(batch_size,1)),tf.linalg.norm(M_prev,axis = 2)) #This is the denominator multiplied norm value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K[.,.] should be of shape [68,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22745, shape=(61, 90), dtype=float32, numpy=\n",
       "array([[2.5932064, 3.2660518, 2.3603058, ..., 2.4679694, 2.3849885,\n",
       "        2.8541474],\n",
       "       [4.0530243, 2.8802643, 3.647146 , ..., 4.4283714, 3.0079472,\n",
       "        3.3189452],\n",
       "       [1.5377616, 2.8815222, 2.4059458, ..., 2.471018 , 1.5910689,\n",
       "        2.978387 ],\n",
       "       ...,\n",
       "       [3.7147613, 3.2942076, 3.3360345, ..., 4.4191713, 2.6649046,\n",
       "        3.3275197],\n",
       "       [2.228442 , 1.5200226, 1.9804798, ..., 1.9989941, 2.4690008,\n",
       "        2.1676097],\n",
       "       [3.3294933, 2.7179575, 2.5504918, ..., 3.2386963, 3.2300858,\n",
       "        2.6896815]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.reshape(k_t,(batch_size,1,M))*M_prev, axis = 2) #This is the dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tf.reduce_sum(tf.reshape(k_t,(batch_size,1,M))*M_prev, axis = 2) /  tf.multiply(tf.reshape(tf.linalg.norm(k_t,axis =1),(batch_size,1)),tf.linalg.norm(M_prev,axis = 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22764, shape=(61, 90), dtype=float32, numpy=\n",
       "array([[0.72554713, 0.8558774 , 0.8145231 , ..., 0.8121951 , 0.75075233,\n",
       "        0.8481599 ],\n",
       "       [0.8719958 , 0.82362616, 0.8887979 , ..., 0.89118814, 0.77267647,\n",
       "        0.91559577],\n",
       "       [0.6571728 , 0.94037795, 0.7830406 , ..., 0.8376081 , 0.75633574,\n",
       "        0.7939925 ],\n",
       "       ...,\n",
       "       [0.85715276, 0.7605742 , 0.75627524, ..., 0.8781578 , 0.8485732 ,\n",
       "        0.69576496],\n",
       "       [0.85452783, 0.7142274 , 0.7975844 , ..., 0.6552204 , 0.66423213,\n",
       "        0.7060655 ],\n",
       "       [0.8778722 , 0.78850293, 0.6741339 , ..., 0.72033393, 0.7926611 ,\n",
       "        0.82019955]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=48, shape=(61, 1), dtype=float32, numpy=\n",
       "array([[0.85407066],\n",
       "       [0.04710746],\n",
       "       [0.6117557 ],\n",
       "       [0.08028185],\n",
       "       [0.04349375],\n",
       "       [0.911795  ],\n",
       "       [0.73365855],\n",
       "       [0.90934324],\n",
       "       [0.63897693],\n",
       "       [0.3613155 ],\n",
       "       [0.77798855],\n",
       "       [0.11972249],\n",
       "       [0.62352276],\n",
       "       [0.85664487],\n",
       "       [0.3572116 ],\n",
       "       [0.5357834 ],\n",
       "       [0.53576124],\n",
       "       [0.08292627],\n",
       "       [0.82766294],\n",
       "       [0.45116186],\n",
       "       [0.6374458 ],\n",
       "       [0.53476226],\n",
       "       [0.60202   ],\n",
       "       [0.00594819],\n",
       "       [0.7454233 ],\n",
       "       [0.31553423],\n",
       "       [0.1317898 ],\n",
       "       [0.7465235 ],\n",
       "       [0.03908086],\n",
       "       [0.34705806],\n",
       "       [0.4855107 ],\n",
       "       [0.12419808],\n",
       "       [0.16215038],\n",
       "       [0.9797547 ],\n",
       "       [0.44559407],\n",
       "       [0.6437837 ],\n",
       "       [0.4934603 ],\n",
       "       [0.30058002],\n",
       "       [0.1892041 ],\n",
       "       [0.8537741 ],\n",
       "       [0.537444  ],\n",
       "       [0.42458856],\n",
       "       [0.0050317 ],\n",
       "       [0.6613847 ],\n",
       "       [0.5910659 ],\n",
       "       [0.8011396 ],\n",
       "       [0.59373665],\n",
       "       [0.1901629 ],\n",
       "       [0.557899  ],\n",
       "       [0.23074627],\n",
       "       [0.82203734],\n",
       "       [0.880064  ],\n",
       "       [0.08302414],\n",
       "       [0.6008104 ],\n",
       "       [0.5732827 ],\n",
       "       [0.53978646],\n",
       "       [0.58080924],\n",
       "       [0.02264225],\n",
       "       [0.06553209],\n",
       "       [0.8875978 ],\n",
       "       [0.19396281]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22771, shape=(61, 90), dtype=float32, numpy=\n",
       "array([[0.01111906, 0.01242825, 0.01199695, ..., 0.01197312, 0.01136101,\n",
       "        0.0123466 ],\n",
       "       [0.01112092, 0.0110956 , 0.01112972, ..., 0.01113097, 0.01106901,\n",
       "        0.01114378],\n",
       "       [0.01035664, 0.01231577, 0.01118561, ..., 0.01156531, 0.01100436,\n",
       "        0.01126081],\n",
       "       ...,\n",
       "       [0.01113098, 0.01106075, 0.01105764, ..., 0.01114631, 0.01112472,\n",
       "        0.01101388],\n",
       "       [0.01238194, 0.01093216, 0.01177167, ..., 0.01037433, 0.01045764,\n",
       "        0.01085324],\n",
       "       [0.01126071, 0.0110672 , 0.01082439, ..., 0.01092183, 0.01107613,\n",
       "        0.01113545]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_vals = tf.exp(beta_t*res)\n",
    "exp_vals / tf.reshape(tf.reduce_sum(exp_vals,axis = 1),(-1,1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22797, shape=(61, 90), dtype=float32, numpy=\n",
       "array([[0.01111906, 0.01242825, 0.01199695, ..., 0.01197312, 0.01136101,\n",
       "        0.0123466 ],\n",
       "       [0.01112092, 0.0110956 , 0.01112972, ..., 0.01113097, 0.01106901,\n",
       "        0.01114378],\n",
       "       [0.01035664, 0.01231577, 0.01118561, ..., 0.01156531, 0.01100436,\n",
       "        0.01126081],\n",
       "       ...,\n",
       "       [0.01113098, 0.01106075, 0.01105764, ..., 0.01114631, 0.01112472,\n",
       "        0.01101388],\n",
       "       [0.01238194, 0.01093216, 0.01177167, ..., 0.01037433, 0.01045764,\n",
       "        0.01085324],\n",
       "       [0.01126071, 0.0110672 , 0.01082439, ..., 0.01092183, 0.01107613,\n",
       "        0.01113545]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ContentFocusing(k_t,M_prev,beta_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Focusing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LocationFocusing( k_t, M_prev, beta_t,    g_t, w_prev, s_t, gamma_t,   K = None):\n",
    "    \n",
    "    '''\n",
    "    Computes the Write Vector for whole batch through Location Attentioning in one go.\n",
    "    \n",
    "    k_t, M_prev, b_t, K : SAME AS IN CONTENT FOCUSING\n",
    "    g_t : (batch_size,1), Interpolation Gate in the range (0,1) emitted by HEAD IN USE.\n",
    "    w_prev : (batch_size,N), Weight Vector produced by the HEAD IN USE at the previous time step.\n",
    "    s_t : (batch_size, len(shift_range)), The weights emitted by the HEAD IN USE that defines the normalized distribution over the allowed integer shifts (which is shift_range object)\n",
    "                \n",
    "    gamma_t : (batch_size,1), Sharpening Factor >= 1    \n",
    "    \n",
    "    RETURNS:\n",
    "    \n",
    "    w_t : (batch_size,N), Final Weight Vector through Location Attentioning\n",
    "    '''\n",
    "    \n",
    "    w_ct = ContentFocusing(k_t, M_prev, beta_t, K)\n",
    "    \n",
    "    batch_size,N,M = M_prev.shape\n",
    "    \n",
    "    #assert w_prev.shape == (N,)\n",
    "    \n",
    "    #Interpolation\n",
    "    w_gt = g_t * w_ct + (1 - g_t) * w_prev\n",
    "    \n",
    "    #Convolutional Shift\n",
    "       \n",
    "    \n",
    "        \n",
    "        #TODO\n",
    "        #The main Hurdle!!\n",
    "    w_hat_t = tf.concat([Convolution(s_t[i],w_gt[i]) for i in range(batch_size)],axis = 0)\n",
    "    #^Of shape [batch_size, N]\n",
    "    \n",
    "    \n",
    "    #Sharpening\n",
    "    powered = tf.pow(w_hat_t, g_t)\n",
    "    w_t = powered / tf.reshape(tf.reduce_sum(powered, axis = 1),(-1,1))\n",
    "    \n",
    "    return w_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gt = g_t * ContentFocusing(k_t, M_prev, beta_t) + (1 - g_t) * w_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22872, shape=(61, 90), dtype=float32, numpy=\n",
       "array([[0.35533756, 0.6894588 , 0.80479175, ..., 0.6349884 , 0.55541885,\n",
       "        0.24350293],\n",
       "       [0.02859625, 0.02614178, 0.03149249, ..., 0.04450782, 0.01449552,\n",
       "        0.0345098 ],\n",
       "       [0.19266987, 0.04535276, 0.01200723, ..., 0.15658332, 0.25237033,\n",
       "        0.05255016],\n",
       "       ...,\n",
       "       [0.13885812, 0.13401778, 0.36846238, ..., 0.05631729, 0.13022679,\n",
       "        0.01310542],\n",
       "       [0.0923833 , 0.13903259, 0.31079543, ..., 0.20548564, 0.32254213,\n",
       "        0.0272678 ],\n",
       "       [0.1789712 , 0.3346631 , 0.2509143 , ..., 0.12973386, 0.2217105 ,\n",
       "        0.04943626]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tf.pow(w_prev,g_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22834, shape=(61, 90), dtype=float32, numpy=\n",
       "array([[0.0111473 , 0.01182031, 0.01198312, ..., 0.01173466, 0.01159663,\n",
       "        0.01077986],\n",
       "       [0.01064577, 0.00924526, 0.0123014 , ..., 0.01967518, 0.00240065,\n",
       "        0.01401496],\n",
       "       [0.01539079, 0.00458834, 0.00084535, ..., 0.01304287, 0.01891349,\n",
       "        0.00531914],\n",
       "       ...,\n",
       "       [0.00844763, 0.00830226, 0.01356698, ..., 0.00535579, 0.00818466,\n",
       "        0.00221195],\n",
       "       [0.00703477, 0.00917124, 0.01505221, ..., 0.01170263, 0.01542002,\n",
       "        0.00303403],\n",
       "       [0.01280224, 0.01976956, 0.016215  , ..., 0.01020945, 0.0148739 ,\n",
       "        0.00497202]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res / tf.reshape(tf.reduce_sum(res, axis = 1),(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22835, shape=(2, 61, 90), dtype=float32, numpy=\n",
       "array([[[0.38866937, 0.7550179 , 0.8815607 , ..., 0.69531703,\n",
       "         0.6081017 , 0.26588655],\n",
       "        [0.50779283, 0.43872762, 0.5898665 , ..., 0.95974493,\n",
       "         0.10845494, 0.67523694],\n",
       "        [0.7172704 , 0.14041567, 0.0143714 , ..., 0.57386804,\n",
       "         0.9468932 , 0.17135894],\n",
       "        ...,\n",
       "        [0.25378418, 0.2446518 , 0.69004726, ..., 0.09696114,\n",
       "         0.23739219, 0.01498735],\n",
       "        [0.21098924, 0.32894778, 0.75411284, ..., 0.49474776,\n",
       "         0.78522277, 0.0516032 ],\n",
       "        [0.52254856, 0.99759245, 0.74277055, ..., 0.37313616,\n",
       "         0.65322316, 0.1279006 ]],\n",
       "\n",
       "       [[0.7121161 , 0.924096  , 0.10493314, ..., 0.41378474,\n",
       "         0.60936666, 0.74778235],\n",
       "        [0.8670503 , 0.00983989, 0.00741589, ..., 0.6879052 ,\n",
       "         0.16938496, 0.49485922],\n",
       "        [0.55171156, 0.9524673 , 0.13141167, ..., 0.13219249,\n",
       "         0.2656126 , 0.17225206],\n",
       "        ...,\n",
       "        [0.0515666 , 0.8248035 , 0.7360097 , ..., 0.7736039 ,\n",
       "         0.6307572 , 0.41747034],\n",
       "        [0.787609  , 0.23768413, 0.33498383, ..., 0.12126458,\n",
       "         0.7531885 , 0.22035062],\n",
       "        [0.2710786 , 0.5118362 , 0.8213043 , ..., 0.02069092,\n",
       "         0.22590387, 0.6333958 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "a.append(w_prev)\n",
    "a.append(w_t)\n",
    "tf.convert_to_tensor(a,dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tackling Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t = tf.nn.softmax(s_t,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22837, shape=(61, 3), dtype=float32, numpy=\n",
       "array([[0.3508521 , 0.35592723, 0.2932207 ],\n",
       "       [0.29765448, 0.2027476 , 0.49959788],\n",
       "       [0.3778228 , 0.19784515, 0.42433208],\n",
       "       [0.26167667, 0.37978873, 0.3585346 ],\n",
       "       [0.25392237, 0.3116903 , 0.4343873 ],\n",
       "       [0.37675145, 0.29659584, 0.32665262],\n",
       "       [0.4504265 , 0.22946675, 0.32010677],\n",
       "       [0.4685757 , 0.28320727, 0.24821702],\n",
       "       [0.27434602, 0.49796346, 0.22769052],\n",
       "       [0.3014842 , 0.4085322 , 0.28998363],\n",
       "       [0.31298846, 0.2481137 , 0.43889785],\n",
       "       [0.3437103 , 0.35235316, 0.30393663],\n",
       "       [0.3123308 , 0.33182576, 0.35584342],\n",
       "       [0.34683648, 0.36951542, 0.2836481 ],\n",
       "       [0.2955191 , 0.25643033, 0.44805053],\n",
       "       [0.42602712, 0.25265813, 0.3213147 ],\n",
       "       [0.46359792, 0.28226194, 0.25414014],\n",
       "       [0.24860227, 0.31895885, 0.43243885],\n",
       "       [0.19122706, 0.42353   , 0.38524297],\n",
       "       [0.32554874, 0.30551052, 0.3689407 ],\n",
       "       [0.41641364, 0.25902247, 0.32456386],\n",
       "       [0.4543084 , 0.23807324, 0.30761835],\n",
       "       [0.25310582, 0.4160357 , 0.33085844],\n",
       "       [0.31432995, 0.30751845, 0.37815157],\n",
       "       [0.30031857, 0.35140964, 0.34827176],\n",
       "       [0.3518329 , 0.42672524, 0.22144188],\n",
       "       [0.33883289, 0.26860324, 0.39256385],\n",
       "       [0.2625283 , 0.4039525 , 0.33351916],\n",
       "       [0.2745088 , 0.34713963, 0.37835148],\n",
       "       [0.41511825, 0.36929512, 0.21558662],\n",
       "       [0.4415438 , 0.28653032, 0.2719259 ],\n",
       "       [0.338387  , 0.23559554, 0.4260175 ],\n",
       "       [0.33924916, 0.24005644, 0.4206944 ],\n",
       "       [0.29286388, 0.35539824, 0.35173795],\n",
       "       [0.29798087, 0.28454003, 0.41747916],\n",
       "       [0.36350933, 0.30918506, 0.32730564],\n",
       "       [0.28189382, 0.35263753, 0.36546862],\n",
       "       [0.30742976, 0.41101906, 0.28155115],\n",
       "       [0.37103367, 0.31337377, 0.3155926 ],\n",
       "       [0.35141024, 0.2881027 , 0.36048707],\n",
       "       [0.39411163, 0.21232015, 0.39356825],\n",
       "       [0.34951952, 0.3358425 , 0.31463805],\n",
       "       [0.40123856, 0.3195285 , 0.2792329 ],\n",
       "       [0.29527155, 0.4145058 , 0.29022264],\n",
       "       [0.5370204 , 0.23196198, 0.23101765],\n",
       "       [0.24753048, 0.34297115, 0.40949842],\n",
       "       [0.33609286, 0.2643807 , 0.3995264 ],\n",
       "       [0.35301858, 0.44586748, 0.2011139 ],\n",
       "       [0.36049297, 0.30776292, 0.33174416],\n",
       "       [0.32244483, 0.21999134, 0.45756376],\n",
       "       [0.44362316, 0.2718184 , 0.28455842],\n",
       "       [0.33059734, 0.42162248, 0.24778013],\n",
       "       [0.31978127, 0.36487198, 0.31534678],\n",
       "       [0.23292613, 0.44930255, 0.3177713 ],\n",
       "       [0.4210403 , 0.28419536, 0.29476437],\n",
       "       [0.27859583, 0.4758619 , 0.24554229],\n",
       "       [0.34625542, 0.429126  , 0.22461854],\n",
       "       [0.4138562 , 0.27492037, 0.31122345],\n",
       "       [0.40099058, 0.18787202, 0.41113743],\n",
       "       [0.53598964, 0.23311354, 0.2308968 ],\n",
       "       [0.5471943 , 0.22299439, 0.22981134]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s_t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22841, shape=(3,), dtype=float32, numpy=array([0.3508521 , 0.35592723, 0.2932207 ], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w_gt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22884, shape=(90,), dtype=float32, numpy=\n",
       "array([0.35533756, 0.6894588 , 0.80479175, 0.08821831, 0.51927435,\n",
       "       0.67886406, 0.03825376, 0.6502476 , 0.41987446, 0.02311977,\n",
       "       0.25427988, 0.24537571, 0.8367311 , 0.08455674, 0.75147593,\n",
       "       0.5446072 , 0.02639749, 0.21034698, 0.6594261 , 0.44869885,\n",
       "       0.14429632, 0.3806105 , 0.20494777, 0.8730608 , 0.11782522,\n",
       "       0.22068135, 0.38754243, 0.8381731 , 0.25545573, 0.44642666,\n",
       "       0.08851904, 0.65640014, 0.39040038, 0.7380051 , 0.43247446,\n",
       "       0.08930185, 0.8780038 , 0.15075652, 0.24732804, 0.3504592 ,\n",
       "       0.4211876 , 0.72341764, 0.00113347, 0.5999049 , 0.14582388,\n",
       "       0.86452305, 0.55796105, 0.788396  , 0.40471986, 0.29379642,\n",
       "       0.05899411, 0.3212133 , 0.800506  , 0.5228989 , 0.16447848,\n",
       "       0.14476994, 0.12447245, 0.65464777, 0.26551908, 0.43885332,\n",
       "       0.29979315, 0.7983517 , 0.18054599, 0.07841583, 0.8827569 ,\n",
       "       0.4798715 , 0.6829637 , 0.9067673 , 0.8259656 , 0.8829714 ,\n",
       "       0.64976615, 0.48315153, 0.7077106 , 0.42768294, 0.8064321 ,\n",
       "       0.60235304, 0.74663323, 0.4593663 , 0.6345709 , 0.47317848,\n",
       "       0.19057588, 0.3224189 , 0.3836338 , 0.16618726, 0.13077079,\n",
       "       0.8444624 , 0.88156706, 0.6349884 , 0.55541885, 0.24350293],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want circular convolution between $s$ and $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_matrix = tf.random.uniform((w.shape[0],w.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22891, shape=(90, 90), dtype=float32, numpy=\n",
       "array([[0.63636076, 0.8686743 , 0.39349306, ..., 0.9716097 , 0.71206   ,\n",
       "        0.36838627],\n",
       "       [0.66289926, 0.8393798 , 0.16666293, ..., 0.52293646, 0.0539335 ,\n",
       "        0.24759817],\n",
       "       [0.42545938, 0.8948518 , 0.47508836, ..., 0.25450087, 0.4378693 ,\n",
       "        0.77868295],\n",
       "       ...,\n",
       "       [0.14270055, 0.4661255 , 0.15323901, ..., 0.6755384 , 0.5056366 ,\n",
       "        0.6806333 ],\n",
       "       [0.4419961 , 0.59564686, 0.45988333, ..., 0.2602501 , 0.7185241 ,\n",
       "        0.32736146],\n",
       "       [0.80200136, 0.73216176, 0.53214264, ..., 0.25621212, 0.58739364,\n",
       "        0.8871223 ]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.convert_to_tensor([1,3,5,7,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a%3\n",
    "#interpret 0 as 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23274, shape=(5,), dtype=int32, numpy=array([1, 0, 2, 1, 0], dtype=int32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odd | Even | Odd\n",
    "1      2     3\n",
    "3      4     5\n",
    "5      6     7 \n",
    "7      8     9\n",
    "9     10     11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(shift_range) == 3, thus, above three columns will repeat untill count reaches upto w.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. To Make the Repeating Columns' Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will be of size [N, len(shift_range)]\n",
    "test = ([i for i in range(1,N*2,2)], [i for i in range(2,2*N+1,2)], [i for i in range(3, 2*N + 2, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_matrix = tf.transpose(tf.convert_to_tensor(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_mat = tf.concat([repeat_matrix for _ in range(int(N/3))],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23296, shape=(90, 90), dtype=int32, numpy=\n",
       "array([[  1,   2,   3, ...,   1,   2,   3],\n",
       "       [  3,   4,   5, ...,   3,   4,   5],\n",
       "       [  5,   6,   7, ...,   5,   6,   7],\n",
       "       ...,\n",
       "       [175, 176, 177, ..., 175, 176, 177],\n",
       "       [177, 178, 179, ..., 177, 178, 179],\n",
       "       [179, 180, 181, ..., 179, 180, 181]], dtype=int32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_p = 92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_p%3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23292, shape=(90, 3), dtype=int32, numpy=\n",
       "array([[  1,   2,   3],\n",
       "       [  3,   4,   5],\n",
       "       [  5,   6,   7],\n",
       "       [  7,   8,   9],\n",
       "       [  9,  10,  11],\n",
       "       [ 11,  12,  13],\n",
       "       [ 13,  14,  15],\n",
       "       [ 15,  16,  17],\n",
       "       [ 17,  18,  19],\n",
       "       [ 19,  20,  21],\n",
       "       [ 21,  22,  23],\n",
       "       [ 23,  24,  25],\n",
       "       [ 25,  26,  27],\n",
       "       [ 27,  28,  29],\n",
       "       [ 29,  30,  31],\n",
       "       [ 31,  32,  33],\n",
       "       [ 33,  34,  35],\n",
       "       [ 35,  36,  37],\n",
       "       [ 37,  38,  39],\n",
       "       [ 39,  40,  41],\n",
       "       [ 41,  42,  43],\n",
       "       [ 43,  44,  45],\n",
       "       [ 45,  46,  47],\n",
       "       [ 47,  48,  49],\n",
       "       [ 49,  50,  51],\n",
       "       [ 51,  52,  53],\n",
       "       [ 53,  54,  55],\n",
       "       [ 55,  56,  57],\n",
       "       [ 57,  58,  59],\n",
       "       [ 59,  60,  61],\n",
       "       [ 61,  62,  63],\n",
       "       [ 63,  64,  65],\n",
       "       [ 65,  66,  67],\n",
       "       [ 67,  68,  69],\n",
       "       [ 69,  70,  71],\n",
       "       [ 71,  72,  73],\n",
       "       [ 73,  74,  75],\n",
       "       [ 75,  76,  77],\n",
       "       [ 77,  78,  79],\n",
       "       [ 79,  80,  81],\n",
       "       [ 81,  82,  83],\n",
       "       [ 83,  84,  85],\n",
       "       [ 85,  86,  87],\n",
       "       [ 87,  88,  89],\n",
       "       [ 89,  90,  91],\n",
       "       [ 91,  92,  93],\n",
       "       [ 93,  94,  95],\n",
       "       [ 95,  96,  97],\n",
       "       [ 97,  98,  99],\n",
       "       [ 99, 100, 101],\n",
       "       [101, 102, 103],\n",
       "       [103, 104, 105],\n",
       "       [105, 106, 107],\n",
       "       [107, 108, 109],\n",
       "       [109, 110, 111],\n",
       "       [111, 112, 113],\n",
       "       [113, 114, 115],\n",
       "       [115, 116, 117],\n",
       "       [117, 118, 119],\n",
       "       [119, 120, 121],\n",
       "       [121, 122, 123],\n",
       "       [123, 124, 125],\n",
       "       [125, 126, 127],\n",
       "       [127, 128, 129],\n",
       "       [129, 130, 131],\n",
       "       [131, 132, 133],\n",
       "       [133, 134, 135],\n",
       "       [135, 136, 137],\n",
       "       [137, 138, 139],\n",
       "       [139, 140, 141],\n",
       "       [141, 142, 143],\n",
       "       [143, 144, 145],\n",
       "       [145, 146, 147],\n",
       "       [147, 148, 149],\n",
       "       [149, 150, 151],\n",
       "       [151, 152, 153],\n",
       "       [153, 154, 155],\n",
       "       [155, 156, 157],\n",
       "       [157, 158, 159],\n",
       "       [159, 160, 161],\n",
       "       [161, 162, 163],\n",
       "       [163, 164, 165],\n",
       "       [165, 166, 167],\n",
       "       [167, 168, 169],\n",
       "       [169, 170, 171],\n",
       "       [171, 172, 173],\n",
       "       [173, 174, 175],\n",
       "       [175, 176, 177],\n",
       "       [177, 178, 179],\n",
       "       [179, 180, 181]], dtype=int32)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23866, shape=(5,), dtype=float32, numpy=\n",
       "array([0.2350838 , 0.20497374, 0.1416037 , 0.23723076, 0.18110798],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = tf.nn.softmax(tf.random.uniform((5,)))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22884, shape=(90,), dtype=float32, numpy=\n",
       "array([0.35533756, 0.6894588 , 0.80479175, 0.08821831, 0.51927435,\n",
       "       0.67886406, 0.03825376, 0.6502476 , 0.41987446, 0.02311977,\n",
       "       0.25427988, 0.24537571, 0.8367311 , 0.08455674, 0.75147593,\n",
       "       0.5446072 , 0.02639749, 0.21034698, 0.6594261 , 0.44869885,\n",
       "       0.14429632, 0.3806105 , 0.20494777, 0.8730608 , 0.11782522,\n",
       "       0.22068135, 0.38754243, 0.8381731 , 0.25545573, 0.44642666,\n",
       "       0.08851904, 0.65640014, 0.39040038, 0.7380051 , 0.43247446,\n",
       "       0.08930185, 0.8780038 , 0.15075652, 0.24732804, 0.3504592 ,\n",
       "       0.4211876 , 0.72341764, 0.00113347, 0.5999049 , 0.14582388,\n",
       "       0.86452305, 0.55796105, 0.788396  , 0.40471986, 0.29379642,\n",
       "       0.05899411, 0.3212133 , 0.800506  , 0.5228989 , 0.16447848,\n",
       "       0.14476994, 0.12447245, 0.65464777, 0.26551908, 0.43885332,\n",
       "       0.29979315, 0.7983517 , 0.18054599, 0.07841583, 0.8827569 ,\n",
       "       0.4798715 , 0.6829637 , 0.9067673 , 0.8259656 , 0.8829714 ,\n",
       "       0.64976615, 0.48315153, 0.7077106 , 0.42768294, 0.8064321 ,\n",
       "       0.60235304, 0.74663323, 0.4593663 , 0.6345709 , 0.47317848,\n",
       "       0.19057588, 0.3224189 , 0.3836338 , 0.16618726, 0.13077079,\n",
       "       0.8444624 , 0.88156706, 0.6349884 , 0.55541885, 0.24350293],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Function for Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convolution(s_t, w_gt):\n",
    "    '''\n",
    "    s_t: (len(shift_range),) ; Shift Weighting of the particualar input\n",
    "    w_gt: (N,) ; W_gt Vector for the particualar input as calculated in the Focusing function\n",
    "    \n",
    "    RETURNS:\n",
    "    \n",
    "    w_hat_t: (1,N) ; Vector found after Circular Convolution of s_t on w_gt\n",
    "    '''\n",
    "    LSR = len(s_t) #length of shift range\n",
    "    test = []\n",
    "    for i in range(LSR):\n",
    "        test.append([j for j in range(i+1, 2*N + i, 2)])\n",
    "    repeat_matrix = tf.transpose(tf.convert_to_tensor(test))\n",
    "    if N%LSR != 0:\n",
    "        repeat_matrix = tf.concat([repeat_matrix,tf.transpose(test[:N%LSR])],axis = 1)\n",
    "\n",
    "    index_mat = np.array(repeat_matrix%LSR,dtype = np.float32)\n",
    "\n",
    "    for i in range(LSR):\n",
    "        index_mat[index_mat == (i+1)%LSR] = s[i]\n",
    "\n",
    "    res = tf.matmul(tf.reshape(w_gt,(1,-1)),index_mat)\n",
    "\n",
    "    final_result = tf.concat([res for _ in range(int(N/LSR))], axis = 1)\n",
    "    if N%LSR != 0:\n",
    "        final_result = tf.concat([final_result,res[:,:N%LSR]], axis = 1)\n",
    "        \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23866, shape=(5,), dtype=float32, numpy=\n",
       "array([0.2350838 , 0.20497374, 0.1416037 , 0.23723076, 0.18110798],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23897, shape=(1, 90), dtype=float32, numpy=\n",
       "array([[8.0356655, 8.2795   , 8.207101 , 8.076358 , 8.281372 , 8.0356655,\n",
       "        8.2795   , 8.207101 , 8.076358 , 8.281372 , 8.0356655, 8.2795   ,\n",
       "        8.207101 , 8.076358 , 8.281372 , 8.0356655, 8.2795   , 8.207101 ,\n",
       "        8.076358 , 8.281372 , 8.0356655, 8.2795   , 8.207101 , 8.076358 ,\n",
       "        8.281372 , 8.0356655, 8.2795   , 8.207101 , 8.076358 , 8.281372 ,\n",
       "        8.0356655, 8.2795   , 8.207101 , 8.076358 , 8.281372 , 8.0356655,\n",
       "        8.2795   , 8.207101 , 8.076358 , 8.281372 , 8.0356655, 8.2795   ,\n",
       "        8.207101 , 8.076358 , 8.281372 , 8.0356655, 8.2795   , 8.207101 ,\n",
       "        8.076358 , 8.281372 , 8.0356655, 8.2795   , 8.207101 , 8.076358 ,\n",
       "        8.281372 , 8.0356655, 8.2795   , 8.207101 , 8.076358 , 8.281372 ,\n",
       "        8.0356655, 8.2795   , 8.207101 , 8.076358 , 8.281372 , 8.0356655,\n",
       "        8.2795   , 8.207101 , 8.076358 , 8.281372 , 8.0356655, 8.2795   ,\n",
       "        8.207101 , 8.076358 , 8.281372 , 8.0356655, 8.2795   , 8.207101 ,\n",
       "        8.076358 , 8.281372 , 8.0356655, 8.2795   , 8.207101 , 8.076358 ,\n",
       "        8.281372 , 8.0356655, 8.2795   , 8.207101 , 8.076358 , 8.281372 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSR = 3\n",
    "test = []\n",
    "for i in range(LSR):\n",
    "    test.append([j for j in range(i+1, 2*N + i, 2)])\n",
    "repeat_matrix = tf.transpose(tf.convert_to_tensor(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(LSR):\n",
    "    index_mat[index_mat == (i+1)%LSR] = s[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution on Whole Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22872, shape=(61, 90), dtype=float32, numpy=\n",
       "array([[0.35533756, 0.6894588 , 0.80479175, ..., 0.6349884 , 0.55541885,\n",
       "        0.24350293],\n",
       "       [0.02859625, 0.02614178, 0.03149249, ..., 0.04450782, 0.01449552,\n",
       "        0.0345098 ],\n",
       "       [0.19266987, 0.04535276, 0.01200723, ..., 0.15658332, 0.25237033,\n",
       "        0.05255016],\n",
       "       ...,\n",
       "       [0.13885812, 0.13401778, 0.36846238, ..., 0.05631729, 0.13022679,\n",
       "        0.01310542],\n",
       "       [0.0923833 , 0.13903259, 0.31079543, ..., 0.20548564, 0.32254213,\n",
       "        0.0272678 ],\n",
       "       [0.1789712 , 0.3346631 , 0.2509143 , ..., 0.12973386, 0.2217105 ,\n",
       "        0.04943626]], dtype=float32)>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22837, shape=(61, 3), dtype=float32, numpy=\n",
       "array([[0.3508521 , 0.35592723, 0.2932207 ],\n",
       "       [0.29765448, 0.2027476 , 0.49959788],\n",
       "       [0.3778228 , 0.19784515, 0.42433208],\n",
       "       [0.26167667, 0.37978873, 0.3585346 ],\n",
       "       [0.25392237, 0.3116903 , 0.4343873 ],\n",
       "       [0.37675145, 0.29659584, 0.32665262],\n",
       "       [0.4504265 , 0.22946675, 0.32010677],\n",
       "       [0.4685757 , 0.28320727, 0.24821702],\n",
       "       [0.27434602, 0.49796346, 0.22769052],\n",
       "       [0.3014842 , 0.4085322 , 0.28998363],\n",
       "       [0.31298846, 0.2481137 , 0.43889785],\n",
       "       [0.3437103 , 0.35235316, 0.30393663],\n",
       "       [0.3123308 , 0.33182576, 0.35584342],\n",
       "       [0.34683648, 0.36951542, 0.2836481 ],\n",
       "       [0.2955191 , 0.25643033, 0.44805053],\n",
       "       [0.42602712, 0.25265813, 0.3213147 ],\n",
       "       [0.46359792, 0.28226194, 0.25414014],\n",
       "       [0.24860227, 0.31895885, 0.43243885],\n",
       "       [0.19122706, 0.42353   , 0.38524297],\n",
       "       [0.32554874, 0.30551052, 0.3689407 ],\n",
       "       [0.41641364, 0.25902247, 0.32456386],\n",
       "       [0.4543084 , 0.23807324, 0.30761835],\n",
       "       [0.25310582, 0.4160357 , 0.33085844],\n",
       "       [0.31432995, 0.30751845, 0.37815157],\n",
       "       [0.30031857, 0.35140964, 0.34827176],\n",
       "       [0.3518329 , 0.42672524, 0.22144188],\n",
       "       [0.33883289, 0.26860324, 0.39256385],\n",
       "       [0.2625283 , 0.4039525 , 0.33351916],\n",
       "       [0.2745088 , 0.34713963, 0.37835148],\n",
       "       [0.41511825, 0.36929512, 0.21558662],\n",
       "       [0.4415438 , 0.28653032, 0.2719259 ],\n",
       "       [0.338387  , 0.23559554, 0.4260175 ],\n",
       "       [0.33924916, 0.24005644, 0.4206944 ],\n",
       "       [0.29286388, 0.35539824, 0.35173795],\n",
       "       [0.29798087, 0.28454003, 0.41747916],\n",
       "       [0.36350933, 0.30918506, 0.32730564],\n",
       "       [0.28189382, 0.35263753, 0.36546862],\n",
       "       [0.30742976, 0.41101906, 0.28155115],\n",
       "       [0.37103367, 0.31337377, 0.3155926 ],\n",
       "       [0.35141024, 0.2881027 , 0.36048707],\n",
       "       [0.39411163, 0.21232015, 0.39356825],\n",
       "       [0.34951952, 0.3358425 , 0.31463805],\n",
       "       [0.40123856, 0.3195285 , 0.2792329 ],\n",
       "       [0.29527155, 0.4145058 , 0.29022264],\n",
       "       [0.5370204 , 0.23196198, 0.23101765],\n",
       "       [0.24753048, 0.34297115, 0.40949842],\n",
       "       [0.33609286, 0.2643807 , 0.3995264 ],\n",
       "       [0.35301858, 0.44586748, 0.2011139 ],\n",
       "       [0.36049297, 0.30776292, 0.33174416],\n",
       "       [0.32244483, 0.21999134, 0.45756376],\n",
       "       [0.44362316, 0.2718184 , 0.28455842],\n",
       "       [0.33059734, 0.42162248, 0.24778013],\n",
       "       [0.31978127, 0.36487198, 0.31534678],\n",
       "       [0.23292613, 0.44930255, 0.3177713 ],\n",
       "       [0.4210403 , 0.28419536, 0.29476437],\n",
       "       [0.27859583, 0.4758619 , 0.24554229],\n",
       "       [0.34625542, 0.429126  , 0.22461854],\n",
       "       [0.4138562 , 0.27492037, 0.31122345],\n",
       "       [0.40099058, 0.18787202, 0.41113743],\n",
       "       [0.53598964, 0.23311354, 0.2308968 ],\n",
       "       [0.5471943 , 0.22299439, 0.22981134]], dtype=float32)>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=95035, shape=(61, 90), dtype=float32, numpy=\n",
       "array([[7.871441  , 7.974221  , 7.932649  , ..., 7.871441  , 7.974221  ,\n",
       "        7.932649  ],\n",
       "       [0.5158037 , 0.510467  , 0.51830107, ..., 0.5158037 , 0.510467  ,\n",
       "        0.51830107],\n",
       "       [2.3188183 , 2.3532133 , 2.3042262 , ..., 2.3188183 , 2.3532133 ,\n",
       "        2.3042262 ],\n",
       "       ...,\n",
       "       [4.7748456 , 4.8092613 , 4.919135  , ..., 4.7748456 , 4.8092613 ,\n",
       "        4.919135  ],\n",
       "       [3.6825395 , 3.713816  , 3.6298757 , ..., 3.6825395 , 3.713816  ,\n",
       "        3.6298757 ],\n",
       "       [2.7274227 , 2.8051114 , 2.7644281 , ..., 2.7274227 , 2.8051114 ,\n",
       "        2.7644281 ]], dtype=float32)>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([Convolution(s_t[i],w_gt[i]) for i in range(batch_size)],axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Location Focusing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=102902, shape=(61, 90), dtype=float32, numpy=\n",
       "array([[0.01110817, 0.01110876, 0.01111641, ..., 0.01110817, 0.01110876,\n",
       "        0.01111641],\n",
       "       [0.01099981, 0.01120573, 0.0111278 , ..., 0.01099981, 0.01120573,\n",
       "        0.0111278 ],\n",
       "       [0.01116099, 0.01097047, 0.01120188, ..., 0.01116099, 0.01097047,\n",
       "        0.01120188],\n",
       "       ...,\n",
       "       [0.01121498, 0.01105435, 0.011064  , ..., 0.01121498, 0.01105435,\n",
       "        0.011064  ],\n",
       "       [0.01111365, 0.01110223, 0.01111746, ..., 0.01111365, 0.01110223,\n",
       "        0.01111746],\n",
       "       [0.01106231, 0.01121623, 0.01105479, ..., 0.01106231, 0.01121623,\n",
       "        0.01105479]], dtype=float32)>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LocationFocusing( k_t, M_prev, beta_t,    g_t, w_prev, s_t, gamma_t,   K = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LocationFocusing( k_t, M_prev, beta_t,    g_t, w_prev, s_t, gamma_t,   K = None):\n",
    "    \n",
    "    '''\n",
    "    Computes the Write Vector for whole batch through Location Attentioning in one go.\n",
    "    \n",
    "    k_t, M_prev, b_t, K : SAME AS IN CONTENT FOCUSING\n",
    "    g_t : (batch_size,1), Interpolation Gate in the range (0,1) emitted by HEAD IN USE.\n",
    "    w_prev : (batch_size,N), Weight Vector produced by the HEAD IN USE at the previous time step.\n",
    "    s_t : (batch_size, len(shift_range)), The weights emitted by the HEAD IN USE that defines the normalized distribution over the allowed integer shifts (which is shift_range object)\n",
    "                \n",
    "    gamma_t : (batch_size,1), Sharpening Factor >= 1    \n",
    "    \n",
    "    RETURNS:\n",
    "    \n",
    "    w_t : (batch_size,N), Final Weight Vector through Location Attentioning\n",
    "    '''\n",
    "    \n",
    "    w_ct = ContentFocusing(k_t, M_prev, beta_t, K)\n",
    "    \n",
    "    batch_size,N,M = M_prev.shape\n",
    "    \n",
    "    #assert w_prev.shape == (N,)\n",
    "    \n",
    "    #Interpolation\n",
    "    w_gt = g_t * w_ct + (1 - g_t) * w_prev\n",
    "    \n",
    "    #Convolutional Shift\n",
    "        #The main Hurdle!!\n",
    "    w_hat_t = tf.concat([Convolution(s_t[i],w_gt[i]) for i in range(batch_size)],axis = 0)\n",
    "    #^Of shape [batch_size, N]\n",
    "    \n",
    "    \n",
    "    #Sharpening\n",
    "    powered = tf.pow(w_hat_t, g_t)\n",
    "    w_t = powered / tf.reshape(tf.reduce_sum(powered, axis = 1),(-1,1))\n",
    "    \n",
    "    return w_t\n",
    "\n",
    "\n",
    "def Convolution(s_t, w_gt):\n",
    "    '''\n",
    "    The Circular Convolutor.\n",
    "    \n",
    "    s_t: (len(shift_range),) ; Shift Weighting of the particualar input\n",
    "    w_gt: (N,) ; W_gt Vector for the particualar input as calculated in the Focusing function\n",
    "    \n",
    "    RETURNS:\n",
    "    \n",
    "    w_hat_t: (1,N) ; Vector found after Circular Convolution of s_t on w_gt\n",
    "    '''\n",
    "    LSR = len(s_t) #length of shift range\n",
    "    test = []\n",
    "    for i in range(LSR):\n",
    "        test.append([j for j in range(i+1, 2*N + i, 2)])\n",
    "    repeat_matrix = tf.transpose(tf.convert_to_tensor(test))\n",
    "    if N%LSR != 0:\n",
    "        repeat_matrix = tf.concat([repeat_matrix,tf.transpose(test[:N%LSR])],axis = 1)\n",
    "\n",
    "    index_mat = np.array(repeat_matrix%LSR,dtype = np.float32)\n",
    "\n",
    "    for i in range(LSR):\n",
    "        index_mat[index_mat == (i+1)%LSR] = s[i]\n",
    "\n",
    "    res = tf.matmul(tf.reshape(w_gt,(1,-1)),index_mat)\n",
    "\n",
    "    final_result = tf.concat([res for _ in range(int(N/LSR))], axis = 1)\n",
    "    if N%LSR != 0:\n",
    "        final_result = tf.concat([final_result,res[:,:N%LSR]], axis = 1)\n",
    "        \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
